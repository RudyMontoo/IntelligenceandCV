{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73dc86f8-94cd-438b-8182-b911e2220999",
   "metadata": {},
   "source": [
    "## NLP Phase 1 Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "495bda1f-d870-4738-867e-a69ddaaaf06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9ab766e-99dc-4f84-a42c-56b4e50f369f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text I am feeling very very happy today!!!...\n"
     ]
    }
   ],
   "source": [
    "text=\"I am feeling very very happy today!!!...\"\n",
    "print(\"Original text\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab73b6a4-c4b0-45b4-b307-7caa6fd0070d",
   "metadata": {},
   "source": [
    "### Step1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e1494b-a531-448a-bc9a-83f08ee00f69",
   "metadata": {},
   "source": [
    "#### convert text into lower case beacause token are consider Happy and happy as differrnt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67629e37-cc00-4c97-988e-3c21cac0b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cd03821-c66c-4e38-aa5b-d5108b53e576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am feeling very very happy today!!!...'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07049451-5280-48dd-ab4e-23efcc1158e5",
   "metadata": {},
   "source": [
    "### Step 2 Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c52f5370-55a2-4fa6-a713-4483d49c19e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Punctuation->  i am feeling very very happy today\n"
     ]
    }
   ],
   "source": [
    "# using re \n",
    "# regular expresion -> \n",
    "import re\n",
    "text=re.sub(r'[^\\w\\s]','',text)\n",
    "print(\"Without Punctuation-> \",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1058ee-362d-44ea-ac88-6e5bde793a32",
   "metadata": {},
   "source": [
    "### Step 3 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f76c37d-0885-479a-a36c-9561214987f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens ['i', 'am', 'feeling', 'very', 'very', 'happy', 'today']\n"
     ]
    }
   ],
   "source": [
    "tokens=text.split()\n",
    "print(\"Tokens\",tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a3b6de-a0ff-4e89-82e9-14b33d900825",
   "metadata": {},
   "source": [
    "### Step 4  Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68add60c-b654-46f1-b57d-7a80c14e20b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=[\"i\",\"am\",\"is\",\"the\",\"a\",\"an\",\"very\"]\n",
    "filtered_tokens=[]\n",
    "for word in tokens:\n",
    "    if word not in stopwords:\n",
    "        filtered_tokens.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddf5fdd3-ef91-4f0c-99d7-8a50b4e17a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feeling', 'happy', 'today']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a8e7c3-0ee9-4b56-92de-3cb44113baa0",
   "metadata": {},
   "source": [
    "###  Step 5 Stemmanization and Lemmanization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d9707d2-86c3-4fd4-98d4-5a9d11476bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Stemming: ['feel', 'happy', 'today']\n"
     ]
    }
   ],
   "source": [
    "def stem(word):\n",
    "    if(word.endswith(\"ing\")):\n",
    "        return word[:-3]\n",
    "    return word\n",
    "stemmed_word=[]\n",
    "for word in filtered_tokens:\n",
    "    stemmed_word.append(stem(word))\n",
    "\n",
    "print(\"After Stemming:\",stemmed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dca18f-32ec-4ea6-89db-0a019ce6c273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ea55d9b-2889-486a-a11c-c016fdbf643f",
   "metadata": {},
   "source": [
    "## NlP Phase 2-> Words to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79068999-1cb6-46aa-9ba1-68a29f296e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b1efd7a-ec59-4626-89a7-aac18038b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences={\n",
    "    \"i am good\",\n",
    "    \"i am happy\",\n",
    "    \"happy today\",\n",
    "    \"i am sad\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1d3156-37bd-4d67-b4c7-b85449e1c3a5",
   "metadata": {},
   "source": [
    "### Vectorizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6265f87-e84d-455e-9c3e-de529aece2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 8 stored elements and shape (4, 5)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vectorizer=CountVectorizer()\n",
    "X= vectorizer.fit_transform(sentences)\n",
    "# learn vocabulory and convert sentence to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78f36f3d-59da-4b76-adba-5f68b7afecdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulory: ['am' 'good' 'happy' 'sad' 'today']\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulory:\",vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b0e7f50-1a23-449b-a49e-ca3bf9c370ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors:\n",
      "[[1 1 0 0 0]\n",
      " [1 0 0 1 0]\n",
      " [1 0 1 0 0]\n",
      " [0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"vectors:\")\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9339eeff-c532-41bc-a863-03c5ce61d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "# Each row=sentence\n",
    "# Each col=word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4501afd-530d-41dd-9256-2c3f5ef7b31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulory: ['also' 'am' 'and' 'good' 'great' 'is' 'learn' 'learninng' 'love' 'ml'\n",
      " 'programming' 'python' 'to' 'with']\n",
      "\n",
      "Matrix:\n",
      "[[0 1 1 1 0 1 0 1 0 0 0 2 0 0]\n",
      " [0 0 0 0 1 1 1 0 0 0 1 1 1 0]\n",
      " [1 0 0 0 0 0 0 0 1 1 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "sentences=[\n",
    "    \"I am learninng python and python is good\",\n",
    "    \"python is a great programming to learn\",\n",
    "    \"i also love ML with python\"\n",
    "]\n",
    "\n",
    "vectorizer=CountVectorizer()\n",
    "x=vectorizer.fit_transform(sentences)\n",
    "print(\"Vocabulory:\",vectorizer.get_feature_names_out())\n",
    "print(\"\\nMatrix:\")\n",
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddf5760-3e45-4e61-8dba-fd6e4f7d890d",
   "metadata": {},
   "source": [
    "### TF IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "716ed203-cc87-4cd3-9280-9c4e529be894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAG OF WORDS treat all word equally\n",
    "# for eg i am learning python, python and python\n",
    "# It will assign huge weight on python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fa7850-a7bc-4387-9fd5-ba4a3ef04778",
   "metadata": {},
   "source": [
    "### What is TF-IDF?\n",
    "TF stands for Term Frequency and denotes the ratio of number of times a particular word appeared in a Document to total number of words in the document.\n",
    "\n",
    "   Term Frequency(TF) = [number of times word appeared / total no of words in a document]\n",
    "Term Frequency values ranges between 0 and 1. If a word occurs more number of times, then it's value will be close to 1.\n",
    "\n",
    "IDF stands for Inverse Document Frequency and denotes the log of ratio of total number of documents/datapoints in the whole dataset to the number of documents that contains the particular word.\n",
    "\n",
    "   Inverse Document Frequency(IDF) = [log(Total number of documents / number of documents that contains the word)]\n",
    "  \n",
    "In IDF, if a word occured in more number of documents and is common across all documents, then it's value will be less and ratio will approaches to 0.\n",
    "\n",
    "Finally:\n",
    "\n",
    "   TF-IDF = Term Frequency(TF) * Inverse Document Frequency(IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07f83e23-65b9-4819-84ba-3d3ad1089e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50a4d720-23e5-469e-8130-78e7ed831c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[\n",
    "    \"I am learninng python and python is good\",\n",
    "    \"python is a great programming to learn\",\n",
    "    \"i also love ML with python\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2bbc738-85ad-4044-9ba3-4a47d3d8bd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer =TfidfVectorizer()\n",
    "X=vectorizer.fit_transform(sentences)\n",
    "# INTERNALLY\n",
    "# build vocabulary\n",
    "# calculate TF\n",
    "# Calculate IDF\n",
    "# multiply tf * idf\n",
    "# generate matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f65f58a-1902-4b20-97c0-e36692c7f84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['also' 'am' 'and' 'good' 'great' 'is' 'learn' 'learninng' 'love' 'ml'\n",
      " 'programming' 'python' 'to' 'with']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7da178b1-d355-436c-be74-dab640fb39f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix\n",
      "[[0.         0.40914568 0.40914568 0.40914568 0.         0.31116583\n",
      "  0.         0.40914568 0.         0.         0.         0.48329606\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.45050407 0.34261996\n",
      "  0.45050407 0.         0.         0.         0.45050407 0.26607496\n",
      "  0.45050407 0.        ]\n",
      " [0.47952794 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.47952794 0.47952794 0.         0.28321692\n",
      "  0.         0.47952794]]\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF matrix\")\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa2a7713-2119-4c93-aaa0-5fd8a3d7c0f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 5) (2971776617.py, line 5)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mTerm Frequency values ranges between 0 and 1. If a word occurs more number of times, then it's value will be close to 1.\u001b[39m\n                                                                                                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 5)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb7f8d-a748-4713-9733-596cb821d127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
